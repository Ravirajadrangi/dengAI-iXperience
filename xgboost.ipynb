{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # support for multi-dimensional arrays and matrices\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('X.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new feature, 0 if cold (<300 Kelvin), 1 if warm\n",
    "\n",
    "def is_warm(features):\n",
    "    warm = []\n",
    "    for observation in features['reanalysis_avg_temp_k']:\n",
    "        if observation < 300:\n",
    "            warm.append(0)\n",
    "        else:\n",
    "            warm.append(1)\n",
    "    return warm\n",
    "\n",
    "warmth = is_warm(X)\n",
    "warmth_test = is_warm(X_test)\n",
    "\n",
    "X['warmth'] = warmth\n",
    "X_test['warmth'] = warmth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove constant columns (std = 0)\n",
    "remove = []\n",
    "for col in X.columns:\n",
    "    if X[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "X.drop(remove, axis=1, inplace=True)\n",
    "X_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting what a Boosting model selects as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cols = X.columns.values.tolist()\n",
    "clf = GradientBoostingRegressor(random_state = 8001)\n",
    "\n",
    "selector = clf.fit(X, y)\n",
    "importances = selector.feature_importances_\n",
    "fs = SelectFromModel(selector, prefit=True)\n",
    "X = fs.transform(X)\n",
    "X_test = fs.transform(X_test)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols = X.shape[1]\n",
    "sortedCols = [col for importance, col  in sorted(zip(importances, Cols))]\n",
    "sortedCols = sortedCols[0:selectedCols]\n",
    "X = pd.DataFrame(X)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X.columns = sortedCols\n",
    "X_test.columns = sortedCols\n",
    "\n",
    "print(sortedCols[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.replace(np.inf, 999999)\n",
    "X = X.replace(-np.inf, -999999)\n",
    "X = X.replace(np.nan, -1)\n",
    "X_test = X_test.replace(np.inf, 999999)\n",
    "X_test = X_test.replace(-np.inf, -999999)\n",
    "X_test = X_test.replace(np.nan, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second round of gradient boosting\n",
    "Cols = X.columns.values.tolist()\n",
    "clf = GradientBoostingRegressor(random_state=1729)\n",
    "selector = clf.fit(X, y)\n",
    "\n",
    "importances = selector.feature_importances_\n",
    "fs = SelectFromModel(selector, prefit=True)\n",
    "X = fs.transform(X)\n",
    "X_test = fs.transform(X_test)\n",
    "print(X.shape, X_test.shape)\n",
    "\n",
    "selectedCols = X.shape[1]\n",
    "sortedCols = [col for importance, col  in sorted(zip(importances, Cols))]\n",
    "sortedCols = sortedCols[0:selectedCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [6,7,8,9], 'min_child_weight': [3,5,7]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick max_depth: 7 and min_child_weight: 5\n",
    "Next we vary n_estimators, subsample, and colsample_bytree\n",
    "\n",
    "### Grid Search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'n_estimators': [75,100,200,300], 'subsample': [0.7,0.8,0.9], 'colsample_bytree': [0.7,0.8,0.9]}\n",
    "ind_params = {'learning_rate': 0.1, 'min_child_weight': 5, 'seed':0, 'max_depth': 7}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "            'max_depth':7, 'min_child_weight':5, 'n_estimators': 300} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['rmse'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'max_depth':7, 'min_child_weight':5} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdmat = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = final_gb.predict(testdmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in y_pred:\n",
    "    print(int(round(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model (cross validation, no tuning grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array for prediction\n",
    "predictedResult = np.zeros(X.shape[0])\n",
    "\n",
    "# Split dataset into k = 10 consecutive folds\n",
    "# Each fold is used once as a validation while the k - 1 remaining folds form the training set\n",
    "kf = KFold(X.shape[0], n_folds=5)\n",
    "\n",
    "testPred = []\n",
    "\n",
    "for trainIndex, testIndex in kf:\n",
    "    trainFold, testFold = X[trainIndex], X[testIndex]\n",
    "    trainFoldTarget, testFoldTarget = y[trainIndex], y[testIndex]\n",
    "    \n",
    "    xgbc = xgb.XGBRegressor(n_estimators = 300, # number of boosted trees\n",
    "                             learning_rate = 0.1, # step size shrinkage used in update to prevent overfitting\n",
    "                             max_depth = 7, # maximum depth of a tree\n",
    "                             subsample = 0.8, # subsample ratio of the training set (Stochastic gradient boosting)\n",
    "                             colsample_bytree = 0.8,\n",
    "                           min_child_weight = 5) # subsample features\n",
    "    \n",
    "    xgbc.fit(trainFold, trainFoldTarget)\n",
    "    xgbpred =xgbc.predict(testFold)\n",
    "\n",
    "    testPred.append(xgbc.predict(X_test))\n",
    "    predictedResult[testIndex] = xgbpred\n",
    "    \n",
    "    # Print the MA\n",
    "    print(mean_absolute_error(testFoldTarget, xgbpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y, predictedResult))\n",
    "testPred = np.average(np.array(testPred), axis =0)\n",
    "#pd.DataFrame({\"ID\": test_id, \"TARGET\": testPred}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in testPred:\n",
    "    print(int(round(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
