{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # support for multi-dimensional arrays and matrices\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('X.csv', index_col=0)\n",
    "y = pd.read_csv('y.csv', header=None, index_col=0)\n",
    "X_test = pd.read_csv('X_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new feature, 0 if cold (<300 Kelvin), 1 if warm\n",
    "\n",
    "def is_warm(features):\n",
    "    warm = []\n",
    "    for observation in features['reanalysis_avg_temp_k']:\n",
    "        if observation < 300:\n",
    "            warm.append(0)\n",
    "        else:\n",
    "            warm.append(1)\n",
    "    return warm\n",
    "\n",
    "warmth = is_warm(X)\n",
    "warmth_test = is_warm(X_test)\n",
    "\n",
    "X['warmth'] = warmth\n",
    "X_test['warmth'] = warmth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 23) (416, 23)\n"
     ]
    }
   ],
   "source": [
    "# remove constant columns (std = 0)\n",
    "remove = []\n",
    "for col in X.columns:\n",
    "    if X[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "X.drop(remove, axis=1, inplace=True)\n",
    "X_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting what a Boosting model selects as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cols = X.columns.values.tolist()\n",
    "clf = GradientBoostingRegressor(random_state = 8001)\n",
    "\n",
    "selector = clf.fit(X, y)\n",
    "importances = selector.feature_importances_\n",
    "fs = SelectFromModel(selector, prefit=True)\n",
    "X = fs.transform(X)\n",
    "X_test = fs.transform(X_test)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols = X.shape[1]\n",
    "sortedCols = [col for importance, col  in sorted(zip(importances, Cols))]\n",
    "sortedCols = sortedCols[0:selectedCols]\n",
    "X = pd.DataFrame(X)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X.columns = sortedCols\n",
    "X_test.columns = sortedCols\n",
    "\n",
    "print(sortedCols[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.replace(np.inf, 999999)\n",
    "X = X.replace(-np.inf, -999999)\n",
    "X = X.replace(np.nan, -1)\n",
    "X_test = X_test.replace(np.inf, 999999)\n",
    "X_test = X_test.replace(-np.inf, -999999)\n",
    "X_test = X_test.replace(np.nan, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second round of gradient boosting\n",
    "Cols = X.columns.values.tolist()\n",
    "clf = GradientBoostingRegressor(random_state=1729)\n",
    "selector = clf.fit(X, y)\n",
    "\n",
    "importances = selector.feature_importances_\n",
    "fs = SelectFromModel(selector, prefit=True)\n",
    "X = fs.transform(X)\n",
    "X_test = fs.transform(X_test)\n",
    "print(X.shape, X_test.shape)\n",
    "\n",
    "selectedCols = X.shape[1]\n",
    "sortedCols = [col for importance, col  in sorted(zip(importances, Cols))]\n",
    "sortedCols = sortedCols[0:selectedCols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [6,7,8,9], 'min_child_weight': [3,5,7]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick max_depth: 7 and min_child_weight: 5\n",
    "Next we vary n_estimators, subsample, and colsample_bytree\n",
    "\n",
    "### Grid Search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'n_estimators': [75,100,200,300], 'subsample': [0.7,0.8,0.9], 'colsample_bytree': [0.7,0.8,0.9]}\n",
    "ind_params = {'learning_rate': 0.1, 'min_child_weight': 5, 'seed':0, 'max_depth': 7}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "            'max_depth':7, 'min_child_weight':5, 'n_estimators': 300} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['rmse'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>18.613302</td>\n",
       "      <td>2.715311</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>0.039431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>18.611960</td>\n",
       "      <td>2.714799</td>\n",
       "      <td>0.496539</td>\n",
       "      <td>0.039945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>18.610680</td>\n",
       "      <td>2.714180</td>\n",
       "      <td>0.490429</td>\n",
       "      <td>0.038934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>18.610113</td>\n",
       "      <td>2.715391</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.037856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>18.610074</td>\n",
       "      <td>2.715261</td>\n",
       "      <td>0.478614</td>\n",
       "      <td>0.037918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "257       18.613302       2.715311         0.502749        0.039431\n",
       "258       18.611960       2.714799         0.496539        0.039945\n",
       "259       18.610680       2.714180         0.490429        0.038934\n",
       "260       18.610113       2.715391         0.484692        0.037856\n",
       "261       18.610074       2.715261         0.478614        0.037918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'max_depth': 7, 'min_child_weight': 5} \n",
    "\n",
    "final_gb = xgb.train(our_params, xgdmat, num_boost_round = 261)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdmat = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = final_gb.predict(testdmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "5\n",
      "13\n",
      "9\n",
      "15\n",
      "9\n",
      "21\n",
      "28\n",
      "18\n",
      "18\n",
      "22\n",
      "45\n",
      "28\n",
      "39\n",
      "44\n",
      "43\n",
      "68\n",
      "55\n",
      "65\n",
      "67\n",
      "39\n",
      "35\n",
      "60\n",
      "34\n",
      "25\n",
      "33\n",
      "31\n",
      "26\n",
      "32\n",
      "29\n",
      "16\n",
      "21\n",
      "21\n",
      "11\n",
      "20\n",
      "16\n",
      "17\n",
      "12\n",
      "13\n",
      "8\n",
      "12\n",
      "11\n",
      "12\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "9\n",
      "6\n",
      "13\n",
      "10\n",
      "6\n",
      "40\n",
      "46\n",
      "45\n",
      "54\n",
      "61\n",
      "57\n",
      "69\n",
      "50\n",
      "75\n",
      "83\n",
      "44\n",
      "58\n",
      "51\n",
      "70\n",
      "70\n",
      "74\n",
      "63\n",
      "48\n",
      "26\n",
      "23\n",
      "34\n",
      "34\n",
      "20\n",
      "15\n",
      "10\n",
      "22\n",
      "11\n",
      "24\n",
      "15\n",
      "29\n",
      "16\n",
      "12\n",
      "16\n",
      "11\n",
      "8\n",
      "16\n",
      "10\n",
      "1\n",
      "8\n",
      "7\n",
      "8\n",
      "5\n",
      "4\n",
      "16\n",
      "13\n",
      "8\n",
      "17\n",
      "14\n",
      "28\n",
      "39\n",
      "49\n",
      "26\n",
      "30\n",
      "48\n",
      "50\n",
      "39\n",
      "32\n",
      "49\n",
      "74\n",
      "79\n",
      "96\n",
      "78\n",
      "56\n",
      "69\n",
      "71\n",
      "64\n",
      "49\n",
      "71\n",
      "75\n",
      "59\n",
      "26\n",
      "38\n",
      "19\n",
      "17\n",
      "16\n",
      "7\n",
      "18\n",
      "10\n",
      "15\n",
      "19\n",
      "14\n",
      "17\n",
      "14\n",
      "13\n",
      "10\n",
      "10\n",
      "9\n",
      "7\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "10\n",
      "5\n",
      "6\n",
      "14\n",
      "16\n",
      "23\n",
      "15\n",
      "31\n",
      "32\n",
      "30\n",
      "34\n",
      "19\n",
      "33\n",
      "27\n",
      "64\n",
      "60\n",
      "51\n",
      "56\n",
      "52\n",
      "51\n",
      "27\n",
      "24\n",
      "66\n",
      "57\n",
      "20\n",
      "11\n",
      "33\n",
      "19\n",
      "20\n",
      "30\n",
      "23\n",
      "8\n",
      "27\n",
      "10\n",
      "10\n",
      "20\n",
      "13\n",
      "15\n",
      "18\n",
      "7\n",
      "12\n",
      "6\n",
      "9\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "9\n",
      "2\n",
      "2\n",
      "9\n",
      "4\n",
      "8\n",
      "9\n",
      "13\n",
      "3\n",
      "7\n",
      "15\n",
      "19\n",
      "40\n",
      "34\n",
      "31\n",
      "16\n",
      "18\n",
      "24\n",
      "41\n",
      "30\n",
      "53\n",
      "47\n",
      "15\n",
      "53\n",
      "62\n",
      "62\n",
      "75\n",
      "70\n",
      "43\n",
      "53\n",
      "51\n",
      "85\n",
      "50\n",
      "29\n",
      "23\n",
      "20\n",
      "19\n",
      "12\n",
      "11\n",
      "12\n",
      "17\n",
      "10\n",
      "12\n",
      "13\n",
      "11\n",
      "10\n",
      "9\n",
      "7\n",
      "6\n",
      "7\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "6\n",
      "5\n",
      "0\n",
      "6\n",
      "1\n",
      "49\n",
      "5\n",
      "15\n",
      "8\n",
      "6\n",
      "13\n",
      "15\n",
      "16\n",
      "5\n",
      "3\n",
      "14\n",
      "3\n",
      "7\n",
      "25\n",
      "14\n",
      "14\n",
      "21\n",
      "14\n",
      "18\n",
      "16\n",
      "17\n",
      "15\n",
      "7\n",
      "4\n",
      "8\n",
      "11\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "13\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "11\n",
      "14\n",
      "6\n",
      "4\n",
      "5\n",
      "12\n",
      "11\n",
      "19\n",
      "14\n",
      "6\n",
      "16\n",
      "18\n",
      "34\n",
      "29\n",
      "4\n",
      "19\n",
      "17\n",
      "17\n",
      "19\n",
      "14\n",
      "18\n",
      "20\n",
      "15\n",
      "10\n",
      "3\n",
      "0\n",
      "3\n",
      "7\n",
      "4\n",
      "2\n",
      "4\n",
      "11\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "10\n",
      "5\n",
      "4\n",
      "1\n",
      "4\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "17\n",
      "11\n",
      "7\n",
      "10\n",
      "19\n",
      "16\n",
      "25\n",
      "6\n",
      "7\n",
      "20\n",
      "23\n",
      "24\n",
      "21\n",
      "28\n",
      "18\n",
      "20\n",
      "13\n",
      "17\n",
      "9\n",
      "11\n",
      "9\n",
      "13\n",
      "6\n",
      "5\n",
      "8\n",
      "7\n",
      "2\n",
      "7\n",
      "12\n",
      "1\n",
      "13\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for pred in y_pred:\n",
    "    print(int(round(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model (cross validation, no tuning grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array for prediction\n",
    "predictedResult = np.zeros(X.shape[0])\n",
    "\n",
    "# Split dataset into k = 10 consecutive folds\n",
    "# Each fold is used once as a validation while the k - 1 remaining folds form the training set\n",
    "kf = KFold(X.shape[0], n_folds=5)\n",
    "\n",
    "testPred = []\n",
    "\n",
    "for trainIndex, testIndex in kf:\n",
    "    trainFold, testFold = X[trainIndex], X[testIndex]\n",
    "    trainFoldTarget, testFoldTarget = y[trainIndex], y[testIndex]\n",
    "    \n",
    "    xgbc = xgb.XGBRegressor(n_estimators = 300, # number of boosted trees\n",
    "                             learning_rate = 0.1, # step size shrinkage used in update to prevent overfitting\n",
    "                             max_depth = 7, # maximum depth of a tree\n",
    "                             subsample = 0.8, # subsample ratio of the training set (Stochastic gradient boosting)\n",
    "                             colsample_bytree = 0.8,\n",
    "                           min_child_weight = 5) # subsample features\n",
    "    \n",
    "    xgbc.fit(trainFold, trainFoldTarget)\n",
    "    xgbpred =xgbc.predict(testFold)\n",
    "\n",
    "    testPred.append(xgbc.predict(X_test))\n",
    "    predictedResult[testIndex] = xgbpred\n",
    "    \n",
    "    # Print the MA\n",
    "    print(mean_absolute_error(testFoldTarget, xgbpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y, predictedResult))\n",
    "testPred = np.average(np.array(testPred), axis =0)\n",
    "#pd.DataFrame({\"ID\": test_id, \"TARGET\": testPred}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in testPred:\n",
    "    print(int(round(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
