{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Baseline Approach\n",
    "\n",
    "I choose to use a DNN Regressor for my first model. Neural networks with multiple layers have be shown to be very flexible in fitting responses that depend nonlinearly on many predictors. I make the assumption that dengue cases can be mapped to from environmental features with some unknown nonlinear function, and so a DNN Regressor should be able to capture information about this mapping. To avoid overfitting, I will stick to about 3 hidden layers, though I will experiment with more, testing model accuracy using a validation set. For this first pass, all real-valued features will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('dengue_features_train.csv')\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting by city\n",
    "\n",
    "train_features_sj = train_features[:936]\n",
    "train_features_iq = train_features[936:]\n",
    "\n",
    "train_labels_sj = train_labels[:936]\n",
    "train_labels_iq = train_labels[936:]\n",
    "\n",
    "test_features_sj = test_features[:260]\n",
    "test_features_iq = test_features[260:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# introducing a datetime feature that contains the unix timestamp\n",
    "\n",
    "def get_timestamp(features):\n",
    "    dt = []\n",
    "    for date in features['week_start_date']:\n",
    "        dt.append(time.mktime(datetime.datetime.strptime(date, '%Y-%m-%d').timetuple()) / 1000)\n",
    "    return dt\n",
    "\n",
    "sj_times = get_timestamp(train_features_sj)\n",
    "iq_times = get_timestamp(train_features_iq)\n",
    "sj_times_test = get_timestamp(test_features_sj)\n",
    "iq_times_test = get_timestamp(test_features_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_features_sj['datetime'] = sj_times\n",
    "train_features_iq['datetime'] = iq_times\n",
    "test_features_sj['datetime'] = sj_times_test\n",
    "test_features_iq['datetime'] = iq_times_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping the city feature and the other features previously used to describe time, now that I have a timestamp\n",
    "\n",
    "train_features_sj = train_features_sj.drop(train_features_sj.columns[[0,1,2,3]], axis=1)\n",
    "train_features_iq = train_features_iq.drop(train_features_iq.columns[[0,1,2,3]], axis=1)\n",
    "\n",
    "test_features_sj = test_features_sj.drop(test_features_sj.columns[[0,1,2,3]], axis=1)\n",
    "test_features_iq = test_features_iq.drop(test_features_iq.columns[[0,1,2,3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filling in missing data\n",
    "\n",
    "train_features_sj.fillna(method='bfill', inplace=True)\n",
    "train_features_iq.fillna(method='bfill', inplace=True)\n",
    "\n",
    "test_features_sj.fillna(method='bfill', inplace=True)\n",
    "test_features_iq.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_sj = train_labels_sj.total_cases\n",
    "train_labels_iq = train_labels_iq.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting data into training set and validation set\n",
    "\n",
    "sj_x_train, sj_x_test, sj_y_train, sj_y_test = model_selection.train_test_split(train_features_sj, train_labels_sj,\n",
    "                                                                               test_size=0.2, random_state=41)\n",
    "\n",
    "iq_x_train, iq_x_test, iq_y_train, iq_y_test = model_selection.train_test_split(train_features_iq, train_labels_iq,\n",
    "                                                                               test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns_city = tf.contrib.learn.infer_real_valued_columns_from_input(train_features_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnnreg_sj = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns_city, hidden_units=[10, 20, 20])\n",
    "dnnreg_iq = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns_city, hidden_units=[10, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-73-674419caf305>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-73-674419caf305>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpz8xri1wp\\model.ckpt-500\n",
      "INFO:tensorflow:Saving checkpoints for 501 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpz8xri1wp\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2713.81, step = 501\n",
      "INFO:tensorflow:global_step/sec: 71.0928\n",
      "INFO:tensorflow:loss = 2713.5, step = 601 (1.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7987\n",
      "INFO:tensorflow:loss = 2713.1, step = 701 (1.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6218\n",
      "INFO:tensorflow:loss = 2712.85, step = 801 (1.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.6026\n",
      "INFO:tensorflow:loss = 2712.46, step = 901 (1.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpz8xri1wp\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2712.12.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x00000256F196B940>, 'hidden_units': [10, 20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=21, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x00000256E9442EA0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnreg_sj.fit(sj_x_train, sj_y_train, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-74-86b95b886a51>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-74-86b95b886a51>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpo3u3qlb7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6.27718e+10, step = 1\n",
      "INFO:tensorflow:global_step/sec: 115.35\n",
      "INFO:tensorflow:loss = 305.402, step = 101 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.211\n",
      "INFO:tensorflow:loss = 305.201, step = 201 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.078\n",
      "INFO:tensorflow:loss = 304.995, step = 301 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.5882\n",
      "INFO:tensorflow:loss = 304.775, step = 401 (1.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.458\n",
      "INFO:tensorflow:loss = 304.593, step = 501 (0.791 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpo3u3qlb7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 304.378.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x00000256F196BB70>, 'hidden_units': [10, 20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=21, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x00000256E9442EA0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnreg_iq.fit(iq_x_train, iq_y_train, steps=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:733: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpz8xri1wp\\model.ckpt-1000\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:733: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpo3u3qlb7\\model.ckpt-600\n"
     ]
    }
   ],
   "source": [
    "predictions_sj = list(dnnreg_sj.predict(sj_x_test, as_iterable=True))\n",
    "predictions_iq = list(dnnreg_iq.predict(iq_x_test, as_iterable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turning predictions into integers, and removing negative values\n",
    "\n",
    "def to_integer(predictions):\n",
    "    predicts = []\n",
    "    for prediction in predictions:\n",
    "        prediction = int(prediction)\n",
    "        if prediction < 0:\n",
    "            prediction = 0\n",
    "        predicts.append(prediction)\n",
    "    return predicts\n",
    "\n",
    "#pred_sj_int = to_integer(predictions_sj)\n",
    "#pred_iq_int = to_integer(predictions_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss sj: 25.686170\n"
     ]
    }
   ],
   "source": [
    "# evaluating model on validation set\n",
    "\n",
    "score_sj = metrics.mean_absolute_error(sj_y_test, pred_sj_int)\n",
    "score_iq = metrics.mean_absolute_error(iq_y_test, pred_iq_int)\n",
    "\n",
    "print('Loss sj: {0:f}'.format(score_sj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss iq: 10.480769\n"
     ]
    }
   ],
   "source": [
    "print('Loss iq: {0:f}'.format(score_iq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-initializing Models to Train Over Entire Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000256EFC0CEB8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpbc6upcog\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000256EFBE9B70>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp5bdhkzf8\n"
     ]
    }
   ],
   "source": [
    "dnnreg_sj = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns_city, hidden_units=[10, 20, 20])\n",
    "dnnreg_iq = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns_city, hidden_units=[10, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-678653c1ec77>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-29-678653c1ec77>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpbc6upcog\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6.27411e+15, step = 1\n",
      "INFO:tensorflow:global_step/sec: 48.6771\n",
      "INFO:tensorflow:loss = 2610.58, step = 101 (2.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.8275\n",
      "INFO:tensorflow:loss = 2614.94, step = 201 (1.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.104\n",
      "INFO:tensorflow:loss = 2614.95, step = 301 (1.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.1034\n",
      "INFO:tensorflow:loss = 2614.95, step = 401 (1.692 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpbc6upcog\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2614.95.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x00000256EF629518>, 'hidden_units': [10, 20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=21, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x00000256E9442EA0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnreg_sj.fit(train_features_sj, train_labels_sj_cases, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-cad0dfbdb534>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-30-cad0dfbdb534>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp5bdhkzf8\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.23985e+15, step = 1\n",
      "INFO:tensorflow:global_step/sec: 100.398\n",
      "INFO:tensorflow:loss = 141.823, step = 101 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.111\n",
      "INFO:tensorflow:loss = 139.464, step = 201 (0.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.565\n",
      "INFO:tensorflow:loss = 139.464, step = 301 (0.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5882\n",
      "INFO:tensorflow:loss = 139.464, step = 401 (1.155 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp5bdhkzf8\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 139.464.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x00000256EF69F860>, 'hidden_units': [10, 20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=21, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x00000256E9442EA0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnreg_iq.fit(train_features_iq, train_labels_iq_cases, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:733: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpbc6upcog\\model.ckpt-500\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:733: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp5bdhkzf8\\model.ckpt-500\n"
     ]
    }
   ],
   "source": [
    "submissions_sj = list(dnnreg_sj.predict(test_features_sj, as_iterable=True))\n",
    "submissions_iq = list(dnnreg_iq.predict(test_features_iq, as_iterable=True))\n",
    "\n",
    "sub_sj_int = to_integer(submissions_sj)\n",
    "sub_iq_int = to_integer(submissions_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea for Improving from the Basline 1\n",
    "\n",
    "The baseline above got a best score of 28.0601\n",
    "\n",
    "The current network uses all features originally in the data, with the exception of the year, week of year, and week start date being replaced by a single datetime. Selecting a meaningful subset of data could greatly help in separating the signal from the noise. In particular, trying to avoid including two variables that are themselves correlated would be a good method to reduce the amount of degrees of freedom of the model, and consequently its flexibility, in order to reduce variance at the potential cost of more bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea for Improving from the Basline 2\n",
    "\n",
    "Since Dengue cases may in fact depend weakly on many predictors, the use of boosting algorithms may be appropriate. sklearn.ensemble has a function GradientBoostingRegressor which may outperform a DNNRegressor in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea for Improving from the Basline 3\n",
    "\n",
    "Since Dengue fever is a mosquito-borne illness, engineering a new feature that captures the prevalence of mosquitos on a given day may prove to be powerful. For instance, if we know that mosquitos do not go out when the temperatures are outside of a certain range, the new feature can depend on this, and if we furthermore know how mosquito density correlates with things like humidity, then the new feature can be made to capture all of this information, while only adding a single degree of freedom to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNNRegressor on a smaller subset of data, and a new engineered feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting a subset of the features\n",
    "X_sj = train_features_sj[['reanalysis_avg_temp_k', \n",
    "                          'reanalysis_dew_point_temp_k', 'reanalysis_min_air_temp_k', \n",
    "                          'reanalysis_specific_humidity_g_per_kg']]\n",
    "y_sj = train_labels_sj\n",
    "X_iq = train_features_iq[['reanalysis_avg_temp_k', \n",
    "                          'reanalysis_dew_point_temp_k', 'reanalysis_min_air_temp_k', \n",
    "                          'reanalysis_specific_humidity_g_per_kg']]\n",
    "y_iq = train_labels_iq\n",
    "\n",
    "# test X values\n",
    "X_sj_test = test_features_sj[['reanalysis_avg_temp_k', \n",
    "                              'reanalysis_dew_point_temp_k', 'reanalysis_min_air_temp_k', \n",
    "                              'reanalysis_specific_humidity_g_per_kg']]\n",
    "\n",
    "X_iq_test = test_features_iq[['reanalysis_avg_temp_k', \n",
    "                              'reanalysis_dew_point_temp_k', 'reanalysis_min_air_temp_k', \n",
    "                              'reanalysis_specific_humidity_g_per_kg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# new feature, 0 if cold (<300 Kelvin), 1 if warm\n",
    "\n",
    "def is_warm(features):\n",
    "    warm = []\n",
    "    for observation in features['reanalysis_avg_temp_k']:\n",
    "        if observation < 300:\n",
    "            warm.append(0)\n",
    "        else:\n",
    "            warm.append(1)\n",
    "    return warm\n",
    "\n",
    "warmth_sj = is_warm(X_sj)\n",
    "warmth_iq = is_warm(X_iq)\n",
    "warmth_sj_test = is_warm(X_sj_test)\n",
    "warmth_iq_test = is_warm(X_iq_test)\n",
    "\n",
    "X_sj['warmth'] = warmth_sj\n",
    "X_iq['warmth'] = warmth_iq\n",
    "X_sj_test['warmth'] = warmth_sj_test\n",
    "X_iq_test['warmth'] = warmth_iq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    }
   ],
   "source": [
    "feature_columns_city = tf.contrib.learn.infer_real_valued_columns_from_input(X_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D44B7D9AC8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp6k7n8jnd\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D44B7D99E8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpzn4osb4q\n"
     ]
    }
   ],
   "source": [
    "dnnreg_sj = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns_city, hidden_units=[10, 20, 20])\n",
    "dnnreg_iq = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns_city, hidden_units=[10, 20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I would do the train/validation set split just by rerunning code above. Omitted here hehe.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-000478593782>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-31-000478593782>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp6k7n8jnd\\model.ckpt.\n",
      "INFO:tensorflow:loss = 11461.2, step = 1\n",
      "INFO:tensorflow:global_step/sec: 29.2952\n",
      "INFO:tensorflow:loss = 2624.79, step = 101 (3.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.9189\n",
      "INFO:tensorflow:loss = 2623.33, step = 201 (2.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1527\n",
      "INFO:tensorflow:loss = 2621.67, step = 301 (2.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5726\n",
      "INFO:tensorflow:loss = 2619.77, step = 401 (2.734 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp6k7n8jnd\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2617.63.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x000001D44B7D9978>, 'hidden_units': [10, 20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=5, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x000001D4494BAEA0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnreg_sj.fit(X_sj, y_sj, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-db31f9a481f0>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-32-db31f9a481f0>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpzn4osb4q\\model.ckpt.\n",
      "INFO:tensorflow:loss = 221.854, step = 1\n",
      "INFO:tensorflow:global_step/sec: 53.8306\n",
      "INFO:tensorflow:loss = 115.304, step = 101 (1.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.1806\n",
      "INFO:tensorflow:loss = 115.245, step = 201 (1.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.181\n",
      "INFO:tensorflow:loss = 115.243, step = 301 (1.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.3941\n",
      "INFO:tensorflow:loss = 115.197, step = 401 (2.094 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpzn4osb4q\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 115.14.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x000001D44E6CFE48>, 'hidden_units': [10, 20, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=5, default_value=None, dtype=tf.float64, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x000001D4494BAEA0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnreg_iq.fit(X_iq, y_iq, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:733: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmp6k7n8jnd\\model.ckpt-500\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\8050116\\AppData\\Local\\conda\\conda\\envs\\iX2017\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:733: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\8050116\\AppData\\Local\\Temp\\tmpzn4osb4q\\model.ckpt-500\n"
     ]
    }
   ],
   "source": [
    "submissions_sj = list(dnnreg_sj.predict(X_sj_test, as_iterable=True))\n",
    "submissions_iq = list(dnnreg_iq.predict(X_iq_test, as_iterable=True))\n",
    "\n",
    "sub_sj_int = to_integer(submissions_sj)\n",
    "sub_iq_int = to_integer(submissions_iq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This model scores 27.3582, an improvement over the baseline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "32\n",
      "33\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "35\n",
      "34\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "34\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "33\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for sub in sub_sj_int:\n",
    "    print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for sub in sub_iq_int:\n",
    "    print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
